{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(1, 100)\n",
    "        self.activ = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(100, 1)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activ(x)\n",
    "        x = self.do(x)\n",
    "        x = self.layer2(x)\n",
    "                        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.rand(1000)-0.4)*3\n",
    "y = x**3 + torch.randn(1)*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "model.train() \n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (val, t) in enumerate(zip(x, y)):\n",
    "        optim.zero_grad()\n",
    "        predict = model(val.unsqueeze(dim=0))\n",
    "        loss = loss_func(predict, t)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self, n_inp, n_out, activation='sigmoid'):\n",
    "        self.w = np.random.randn(n_out, n_inp) * 0.1\n",
    "        self.b = np.random.randn(n_out, 1) * 0.1\n",
    "        if activation == 'sigmoid':\n",
    "            self.activ = sigmoid\n",
    "        if activation == 'relu':\n",
    "            self.activ = relu\n",
    "        elif activation == 'None':\n",
    "            self.activ = None\n",
    "        else:\n",
    "            raise Exception(f'Unknown activation \"{activation}\"')\n",
    "        self._clear_state()\n",
    "\n",
    "    def _clear_state(self):\n",
    "        self.lin = None\n",
    "        self.inp = None\n",
    "        self.d_w = None\n",
    "        self.d_b = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.inp = x\n",
    "        self.lin = np.dot(self.w, x) + self.b\n",
    "        activ = self.activ(self.lin) if self.activ is not None else self.lin\n",
    "\n",
    "        return activ\n",
    "\n",
    "    def backward(self, grad): # grad = d L / d z    Dout \n",
    "        # grad * dz / d lin\n",
    "        if self.activ == sigmoid:\n",
    "            grad_lin = sigmoid_backward(grad, self.lin) \n",
    "        elif self.activ == relu:\n",
    "            grad_lin = relu_backward(grad, self.lin)\n",
    "        else:\n",
    "            grad_lin = grad\n",
    "        # grad_lin * d lin / d w \n",
    "        m = self.inp.shape[1]\n",
    "        self.d_w = np.dot(grad_lin, self.inp.T) / m    # d_in dOut\n",
    "        # grad_lin * d lin / d b \n",
    "        self.d_b = np.sum(grad_lin, axis=1, keepdims=True) / m\n",
    "\n",
    "        grad = np.dot(self.w.T, grad_lin)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDMomentum1:\n",
    "    def __init__(self, model: LinearLayer, lr=0.001, momentum=0.99):\n",
    "        self.lr = lr\n",
    "        self.m = momentum\n",
    "        self.model = model\n",
    "\n",
    "        self.vel_w = np.zeros_like(model.w)\n",
    "        self.vel_b = np.zeros_like(model.b)\n",
    "\n",
    "    def step(self):\n",
    "        self.vel_w = self.m * self.vel_w - self.lr * self.model.d_w\n",
    "        self.vel_b = self.m * self.vel_b - self.lr * self.model.d_b\n",
    "\n",
    "        self.model.w += self.vel_w\n",
    "        self.model.b += self.vel_b\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.model.d_w = np.zeros_like(self.model.d_w)\n",
    "        self.model.d_b = np.zeros_like(self.model.d_b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdamOptim():\n",
    "    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.m_dw, self.v_dw = 0, 0\n",
    "        self.m_db, self.v_db = 0, 0\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.eta = eta\n",
    "    def update(self, t, w, b, dw, db):\n",
    "        ## dw, db из текущей минибатча\n",
    "        ## momentum beta 1\n",
    "        # *** веса *** #\n",
    "        self.m_dw = self.beta1*self.m_dw + (1-self.beta1)*dw\n",
    "        # *** смещения *** #\n",
    "        self.m_db = self.beta1*self.m_db + (1-self.beta1)*db\n",
    "\n",
    "        ## rms beta 2\n",
    "        # *** веса *** #\n",
    "        self.v_dw = self.beta2*self.v_dw + (1-self.beta2)*(dw**2)\n",
    "        # *** смещения *** #\n",
    "        self.v_db = self.beta2*self.v_db + (1-self.beta2)*(db)\n",
    "\n",
    "        ## коррекция смещения\n",
    "        m_dw_corr = self.m_dw/(1-self.beta1**t)\n",
    "        m_db_corr = self.m_db/(1-self.beta1**t)\n",
    "        v_dw_corr = self.v_dw/(1-self.beta2**t)\n",
    "        v_db_corr = self.v_db/(1-self.beta2**t)\n",
    "\n",
    "        ## обновить веса и смещения\n",
    "        w = w - self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n",
    "        b = b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n",
    "        return w, b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение квадратного уравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QuadraticEquationDataset(Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a = torch.randn(1)\n",
    "        b = torch.randn(1)\n",
    "        c = torch.randn(1)\n",
    "\n",
    "        D = b**2 - 4*a*c\n",
    "        if D < 0:\n",
    "            x1 = float('nan')\n",
    "            x2 = float('nan')\n",
    "        else:\n",
    "            x1 = (-b + torch.sqrt(D)) / (2*a)\n",
    "            x2 = (-b - torch.sqrt(D)) / (2*a)\n",
    "\n",
    "        return torch.Tensor([a, b, c]), torch.Tensor([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = QuadraticEquationDataset(num_samples=1000)\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                          #batch_size=32,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          )\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          #batch_size=32,\n",
    "                                          shuffle=True, \n",
    "                                          num_workers=2, \n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticEquationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuadraticEquationModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(3, 16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(16, 8)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(8, 2)\n",
    "        self.do = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.do(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuadraticEquationModel()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, t) in enumerate(trainloader, 0):\n",
    "        optim.zero_grad()\n",
    "        predict = model(inputs)\n",
    "        print(predict)\n",
    "        loss = loss_func(predict, t)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        predicted = outputs\n",
    "        print(predicted, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
